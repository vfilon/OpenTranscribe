# docker-compose.gpu-scale.yml
# Optional overlay for multi-GPU worker scaling
#
# This overlay provides full service definition for celery-worker-gpu-scaled,
# enabling parallel GPU workers on a dedicated GPU device for significantly
# increased transcription throughput on systems with multiple GPUs.
#
# Usage:
#   ./opentr.sh start dev --gpu-scale
#   OR
#   docker compose -f docker-compose.yml -f docker-compose.override.yml -f docker-compose.gpu-scale.yml up
#
# Note: This file contains the complete service definition, including build,
# volumes, and GPU configuration. The service is not defined in base docker-compose.yml
# to ensure compatibility with macOS and CPU-only systems.
#
# Configuration:
#   Set these variables in your .env file:
#   - GPU_SCALE_ENABLED=true          # Enable GPU scaling (default: false)
#   - GPU_SCALE_DEVICE_ID=2           # GPU device ID to use (default: 2)
#   - GPU_SCALE_WORKERS=4             # Number of parallel workers (default: 4)
#
# Example Hardware Setup:
#   GPU 0: NVIDIA RTX A6000 (49GB)    - Running LLM model
#   GPU 1: RTX 3080 Ti (12GB)         - Default single worker (disabled when scaling enabled)
#   GPU 2: NVIDIA RTX A6000 (49GB)    - Scaled workers (4 parallel in single container)

services:
  # Disable the default single GPU worker when scaling is enabled
  celery-worker:
    scale: 0

  # Scaled GPU Worker - GPU-specific settings only
  # Base definition in docker-compose.yml
  # Image/build/volumes from override.yml (dev) or prod.yml/offline.yml
  celery-worker-gpu-scaled:
    scale: 1  # Enable this service (base has scale: 0)
    command: >
      celery -A app.core.celery worker
      -Q gpu
      --concurrency=${GPU_SCALE_WORKERS:-4}
      --prefetch-multiplier=${GPU_SCALE_WORKERS:-4}
      --max-tasks-per-child=10
      -n gpu-scaled@%h
      --loglevel=info
    environment:
      # GPU-specific environment variable
      - CUDA_VISIBLE_DEVICES=${GPU_SCALE_DEVICE_ID:-2}
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.core.celery inspect ping -d gpu-scaled@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${GPU_SCALE_DEVICE_ID:-2}"]
              capabilities: [gpu]
