<div align="center">
  <img src="../../../assets/logo-banner.png" alt="OpenTranscribe Logo" width="250">
  
  # Services Layer Documentation
</div>

The services layer provides a clean abstraction for business logic, separating it from API endpoints and database operations. This layer orchestrates complex operations, manages transactions, and provides reusable business functionality.

## ðŸŽ¯ Service Layer Principles

### Design Goals
- **Business Logic Encapsulation**: Keep complex operations out of endpoints
- **Reusability**: Share common operations across multiple endpoints
- **Transaction Management**: Handle database transactions consistently
- **External Service Integration**: Manage third-party API interactions
- **Error Handling**: Provide consistent error handling patterns
- **Testing**: Enable easier unit testing of business logic

### Architecture Pattern
```
API Endpoints â†’ Service Layer â†’ Data Layer (Models/External APIs)
     â†“              â†“                    â†“
  HTTP Logic   Business Logic      Data Operations
```

## ðŸ“ Service Structure

```
services/
â”œâ”€â”€ file_service.py                    # File management operations
â”œâ”€â”€ file_cleanup_service.py            # File recovery and cleanup operations
â”œâ”€â”€ transcription_service.py           # Transcription workflow management
â”œâ”€â”€ llm_service.py                     # Multi-provider LLM integration with intelligent context processing
â”œâ”€â”€ opensearch_summary_service.py      # AI summary search and indexing operations
â”œâ”€â”€ minio_service.py                   # Object storage operations
â”œâ”€â”€ opensearch_service.py              # Search and indexing operations
â”œâ”€â”€ analytics_service.py               # Server-side analytics computation service
â”œâ”€â”€ error_categorization_service.py    # Error classification and user guidance service
â”œâ”€â”€ formatting_service.py              # Data formatting and display service
â”œâ”€â”€ profile_embedding_service.py       # Voice embedding and speaker similarity service
â”œâ”€â”€ smart_speaker_suggestion_service.py # Intelligent speaker suggestion consolidation service
â”œâ”€â”€ speaker_status_service.py          # Speaker verification status management service
â”œâ”€â”€ task_filtering_service.py          # Task and data filtering optimization service
â””â”€â”€ youtube_service.py                 # Universal media URL processing (YouTube, Vimeo, Twitter/X, TikTok, etc.)
```

## ðŸ”§ Service Design Patterns

### Base Service Pattern
```python
class BaseService:
    """Base service class with common patterns."""
    
    def __init__(self, db: Session):
        self.db = db
    
    def _validate_user_access(self, resource, user: User) -> None:
        """Common access validation pattern."""
        if resource.user_id != user.id and not user.is_superuser:
            raise ErrorHandler.unauthorized_error("Access denied")
    
    def _handle_database_error(self, operation: str, error: Exception):
        """Common database error handling."""
        logger.error(f"Database error in {operation}: {error}")
        self.db.rollback()
        raise ErrorHandler.database_error(operation, error)
```

### Service Method Pattern
```python
def service_method(self, data: InputSchema, user: User) -> OutputModel:
    """Standard service method pattern."""
    try:
        # 1. Validation
        self._validate_input(data)
        
        # 2. Authorization
        self._check_permissions(user)
        
        # 3. Business Logic
        result = self._perform_operation(data)
        
        # 4. Database Transaction
        self.db.commit()
        
        # 5. Return Result
        return result
        
    except Exception as e:
        self.db.rollback()
        raise self._handle_error(e)
```

## ðŸ“‚ File Service (`file_service.py`)

### Purpose
Manages all file-related operations including upload, metadata management, and file lifecycle.

### Key Operations
```python
class FileService:
    async def upload_file(self, file: UploadFile, user: User) -> MediaFile:
        """Complete file upload pipeline."""
        # Validation, storage, database record creation
    
    def get_user_files(self, user: User, filters: dict) -> List[MediaFile]:
        """Retrieve files with advanced filtering."""
        # Query building, permission checking, filtering
    
    def update_file_metadata(self, file_id: int, updates: MediaFileUpdate, user: User) -> MediaFile:
        """Update file metadata with validation."""
        # Authorization, validation, database update
    
    def delete_file(self, file_id: int, user: User) -> None:
        """Complete file deletion (storage + database)."""
        # Authorization, storage cleanup, database deletion
```

### Usage Example
```python
# In API endpoint
@router.post("/files", response_model=MediaFileSchema)
async def upload_file(
    file: UploadFile = File(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    file_service = FileService(db)
    return await file_service.upload_file(file, current_user)
```

### Features
- **Complete Upload Pipeline**: Validation â†’ Storage â†’ Database â†’ Task Dispatch
- **Advanced Filtering**: Complex query building with multiple filter criteria
- **Permission Management**: User ownership validation
- **Storage Integration**: MinIO operations with error handling
- **Tag Management**: File tagging operations
- **Statistics**: User file statistics and analytics

## ðŸŽ™ï¸ Transcription Service (`transcription_service.py`)

### Purpose
Orchestrates transcription workflows, manages AI processing tasks, and handles speaker management.

### Key Operations
```python
class TranscriptionService:
    def start_transcription(self, file_id: int, user: User) -> Dict[str, Any]:
        """Initiate transcription process."""
        # Validation, task creation, Celery dispatch
    
    def get_transcription_status(self, file_id: int, user: User) -> Dict[str, Any]:
        """Get detailed transcription progress."""
        # Task status, progress tracking, error reporting
    
    def update_transcript_segments(self, file_id: int, updates: List[TranscriptSegmentUpdate], user: User) -> List[TranscriptSegment]:
        """Bulk update transcript segments."""
        # Authorization, validation, batch updates
    
    def merge_speakers(self, primary_id: int, secondary_id: int, user: User) -> Speaker:
        """Merge two speakers across all segments."""
        # Complex database operations, referential integrity
```

### Workflow Management
```python
# Transcription Pipeline
def start_transcription(self, file_id: int, user: User):
    # 1. Validate file exists and is processable
    file_obj = self._validate_file_for_transcription(file_id, user)
    
    # 2. Check current status
    if file_obj.status not in [FileStatus.PENDING, FileStatus.ERROR]:
        raise ValidationError("File cannot be transcribed in current state")
    
    # 3. Dispatch background task
    task = transcribe_audio_task.delay(file_id)
    
    # 4. Return task information
    return {"task_id": task.id, "status": "started"}
```

### Features
- **Task Orchestration**: Celery task management and monitoring
- **Progress Tracking**: Real-time transcription progress
- **Speaker Management**: AI-generated speaker identification and merging
- **Segment Editing**: Transcript text and timing modifications
- **Cross-file Analytics**: Speaker consistency across multiple files
- **Error Recovery**: Robust error handling and retry mechanisms

## ðŸ¤– LLM Service (`llm_service.py`)

### Purpose
Provides unified interface for multiple LLM providers with intelligent context processing for transcript summarization and speaker identification.

### Key Features
```python
async def generate_summary(transcript: str, speaker_data: Dict[str, Any]) -> Dict[str, Any]:
    """Generate BLUF format summary with intelligent section processing."""
    
    # Automatic context detection and chunking
    context_length = await self.get_model_context_length()
    chunks = self._chunk_transcript_intelligently(transcript, context_length)
    
    if len(chunks) == 1:
        # Single-pass processing for short transcripts
        return await self._process_single_section(chunks[0])
    else:
        # Multi-section processing for long transcripts
        section_summaries = []
        for chunk in chunks:
            section_summary = await self._summarize_transcript_section(chunk)
            section_summaries.append(section_summary)
        
        # Stitch sections into comprehensive final summary
        return await self._stitch_section_summaries(section_summaries)
```

### Supported Providers
- **vLLM**: Local high-performance inference
- **OpenAI**: GPT-4, GPT-3.5-turbo
- **Ollama**: Local consumer GPU inference
- **Anthropic**: Claude models
- **OpenRouter**: Multi-provider gateway

### Intelligent Context Processing
- **Automatic Detection**: Queries model endpoints for actual context limits
- **Smart Chunking**: Splits at natural boundaries (speakers, topics, sentences)
- **Section Analysis**: Each chunk processed with full context awareness
- **Summary Stitching**: Combines sections into comprehensive BLUF format
- **Universal Compatibility**: Works with 4K to 200K+ token models

## ðŸ—„ï¸ MinIO Service (`minio_service.py`)

### Purpose
Handles all object storage operations including file upload, download, streaming, and management.

### Key Operations
```python
def upload_file(file_content: IO, file_size: int, object_name: str, content_type: str) -> None:
    """Upload file to MinIO storage."""
    
def download_file(object_name: str) -> Tuple[IO, int, str]:
    """Download file from MinIO storage."""
    
def get_file_stream(object_name: str, range_header: str = None) -> Iterator[bytes]:
    """Stream file with range support for video playback."""
    
def delete_file(object_name: str) -> None:
    """Delete file from MinIO storage."""
    
def get_file_url(object_name: str, expires: int = 3600) -> str:
    """Generate presigned URL for file access."""
```

### Streaming Features
```python
def get_file_stream(object_name: str, range_header: str = None):
    """Advanced streaming with HTTP range support."""
    # Parse range header for video seeking
    # Stream file chunks efficiently
    # Support partial content responses (206)
    # Handle content-length and content-range headers
```

### Features
- **Efficient Upload/Download**: Chunked file operations
- **Video Streaming**: HTTP range request support for video players
- **Presigned URLs**: Secure temporary file access
- **Error Handling**: Comprehensive MinIO error handling
- **Metadata Management**: File metadata and content-type handling

## ðŸ§¹ File Cleanup Service (`file_cleanup_service.py`)

### Purpose
Provides automated file recovery, cleanup operations, and system health monitoring for files stuck in processing or error states.

### Key Operations
```python
class FileCleanupService:
    def run_cleanup_cycle(self) -> Dict[str, Any]:
        """Run a complete cleanup cycle detecting and recovering stuck files."""
        
    def force_cleanup_orphaned_files(self, db: Session, dry_run: bool = False) -> Dict[str, Any]:
        """Force cleanup of orphaned files (admin operation)."""
        
    def get_cleanup_statistics(self, db: Session) -> Dict[str, Any]:
        """Get current cleanup statistics and system health metrics."""
```

### Auto-Recovery Features
```python
def _attempt_file_recovery(self, db: Session, file_id: int) -> bool:
    """Attempt to recover a single stuck file with intelligent retry logic."""
    # Check recovery attempt limits
    if media_file.recovery_attempts >= self.max_recovery_attempts:
        # Mark as permanently orphaned and eligible for force deletion
        media_file.status = FileStatus.ORPHANED
        media_file.force_delete_eligible = True
        return False
    
    # Use enhanced recovery logic from task_utils
    return recover_stuck_file(db, file_id)
```

### Health Monitoring
```python
def _generate_health_recommendations(self, db: Session) -> List[str]:
    """Generate system health recommendations based on file states."""
    recommendations = []
    
    # Calculate error rates and health metrics
    error_rate = status_counts.get('error', 0) / max(sum(status_counts.values()), 1)
    if error_rate > 0.1:  # More than 10% error rate
        recommendations.append(
            f"High error rate detected: {error_rate:.1%} of files are in error state. "
            "Consider investigating processing pipeline health."
        )
    
    return recommendations
```

### Features
- **Automatic Stuck File Detection**: Identifies files stuck in processing or pending states
- **Intelligent Recovery**: Multi-step recovery process with retry limits
- **Health Monitoring**: System health metrics and recommendations
- **Force Cleanup**: Admin tools for removing orphaned files
- **Statistics Tracking**: Comprehensive cleanup statistics and performance metrics
- **Scheduled Operations**: Designed for periodic background execution

### Integration with Task System
The cleanup service works closely with the new cleanup tasks and enhanced task utilities:
- Uses `check_for_stuck_files()` from `task_utils.py` for detection
- Calls `recover_stuck_file()` for automated recovery
- Integrates with `cancel_active_task()` for safe task cancellation
- Provides statistics for monitoring and alerting systems

## ðŸ“Š Analytics Service (`analytics_service.py`)

### Purpose
Provides comprehensive server-side analytics computation for media files including speaker analytics, conversation flow analysis, and meeting efficiency metrics.

### Key Operations
```python
class AnalyticsService:
    @staticmethod
    def compute_analytics(db: Session, media_file_id: int) -> Optional[Dict[str, Any]]:
        """Compute comprehensive analytics for a media file."""
        # Speaker talk time analysis, interruption detection, turn-taking patterns

    @staticmethod
    def save_analytics(db: Session, media_file_id: int, analytics_data: Dict[str, Any]) -> bool:
        """Save computed analytics to the database."""
        # Store analytics with user association

    @staticmethod
    def refresh_analytics(db: Session, media_file_id: int) -> bool:
        """Refresh analytics by recomputing them."""
        # Recompute and update existing analytics
```

### Analytics Features
- **Speaker Talk Time Analysis**: Percentage breakdowns and total speaking time
- **Interruption Detection**: Frequency tracking and pattern analysis
- **Turn-Taking Patterns**: Conversation flow and speaker interaction analysis
- **Question Frequency**: Track question asking by speaker
- **Speaking Pace**: Words per minute calculations
- **Silence Ratio**: Meeting efficiency analysis
- **Word Count Statistics**: Comprehensive word usage across speakers

## ðŸŽ¨ Formatting Service (`formatting_service.py`)

### Purpose
Centralizes all data formatting logic for consistent display across the application, handling dates, durations, file sizes, and speaker information.

### Key Operations
```python
class FormattingService:
    @staticmethod
    def format_duration(seconds: float) -> str:
        """Format seconds to MM:SS format."""

    @staticmethod
    def format_bytes_detailed(size_bytes: int) -> str:
        """Format file size with appropriate units (B, KB, MB, GB)."""

    @staticmethod
    def format_speaker_name(speaker: Speaker) -> str:
        """Format speaker name with verification status indicators."""

    @staticmethod
    def get_status_badge_class(status: str) -> str:
        """Generate CSS class for status badges."""
```

### Formatting Features
- **Duration Formatting**: Seconds to MM:SS and detailed time formats
- **File Size Formatting**: Intelligent unit selection with precision
- **Date and Time**: Timezone-aware formatting with relative time
- **Speaker Name Resolution**: Fallback handling for unknown speakers
- **Status Badge Classes**: UI consistency for status indicators
- **File Age Calculation**: Human-readable relative time display

## ðŸ¤– Smart Speaker Suggestion Service (`smart_speaker_suggestion_service.py`)

### Purpose
Implements intelligent speaker identification with consolidated suggestions, priority-based filtering, and automated profile matching.

### Key Operations
```python
class SmartSpeakerSuggestionService:
    @staticmethod
    def get_consolidated_suggestions(db: Session, speaker_id: int, user_id: int) -> List[ConsolidatedSuggestion]:
        """Get consolidated speaker suggestions with intelligent filtering."""
        # Profile-based suggestions prioritized over individual matches

    @staticmethod
    def filter_and_prioritize_suggestions(suggestions: List[Dict[str, Any]]) -> List[ConsolidatedSuggestion]:
        """Filter out unlabeled speakers and consolidate by name."""
        # Remove SPEAKER_XX format names and consolidate duplicates
```

### Smart Features
- **Profile Prioritization**: Verified profiles prioritized over individual matches
- **Intelligent Consolidation**: Duplicate speaker names merged into single suggestions
- **Unlabeled Filtering**: Automatic removal of SPEAKER_XX format names
- **Confidence Scoring**: Advanced confidence calculation with multiple factors
- **Auto-Accept Logic**: High-confidence suggestions marked for automatic acceptance

## ðŸ”— Profile Embedding Service (`profile_embedding_service.py`)

### Purpose
Manages voice embeddings for speaker profiles, enabling cross-video speaker recognition through vector similarity matching.

### Key Operations
```python
class ProfileEmbeddingService:
    @staticmethod
    def add_speaker_to_profile_embedding(db: Session, speaker_id: int, profile_id: int) -> bool:
        """Add speaker's voice embedding to profile's consolidated embedding."""

    @staticmethod
    def calculate_profile_similarity(db: Session, speaker_embedding: List[float], user_id: int) -> List[Dict[str, Any]]:
        """Calculate similarity between speaker and all user profiles."""
```

### Embedding Features
- **Voice Fingerprinting**: Advanced voice similarity using vector embeddings
- **Cross-Video Matching**: Identify same speakers across different recordings
- **Consolidated Embeddings**: Profile-level voice signatures from multiple recordings
- **Similarity Scoring**: Cosine similarity with confidence thresholds
- **Automatic Profile Updates**: Real-time embedding consolidation

## ðŸ·ï¸ Speaker Status Service (`speaker_status_service.py`)

### Purpose
Manages comprehensive speaker verification status with computed fields for optimized UI display.

### Key Operations
```python
class SpeakerStatusService:
    @staticmethod
    def add_computed_status(speaker: Speaker) -> None:
        """Add computed status fields to speaker object."""
        # Verification status, suggestion availability, confidence levels

    @staticmethod
    def get_verification_status(speaker: Speaker) -> str:
        """Get human-readable verification status."""
```

### Status Features
- **Verification Tracking**: Comprehensive verification status management
- **Computed Fields**: UI-optimized fields added to speaker objects
- **Status Indicators**: Human-readable status text for display
- **Suggestion Availability**: Track whether suggestions are available

## ðŸ”§ Error Categorization Service (`error_categorization_service.py`)

### Purpose
Provides intelligent error classification with user-friendly suggestions and retry guidance for improved error handling.

### Key Operations
```python
class ErrorCategorizationService:
    @staticmethod
    def get_error_info(error_message: str) -> Dict[str, Any]:
        """Categorize error and provide user-friendly information."""
        # Error category, suggestions, retry guidance

    @staticmethod
    def categorize_error(error_message: str) -> str:
        """Categorize error into predefined categories."""
```

### Error Features
- **Intelligent Classification**: Pattern-based error categorization
- **User-Friendly Suggestions**: Actionable guidance for error resolution
- **Retry Guidance**: Determine if errors are retryable
- **Category-Specific Advice**: Tailored suggestions based on error type

## ðŸŽ¬ YouTube Service (`youtube_service.py`)

### Purpose
Provides universal media download and processing from 1000+ video platforms (YouTube, Vimeo, Twitter/X, TikTok, etc.) using yt-dlp. Handles URL validation, video downloading, metadata extraction, and integration with the media processing pipeline.

### Key Operations
```python
class YouTubeService:
    def is_valid_youtube_url(self, url: str) -> bool:
        """Validate if URL is a valid URL for processing (supports any HTTP/HTTPS URL)."""
        # Accepts any URL and lets yt-dlp handle platform-specific validation
    
    def extract_video_info(self, url: str) -> dict[str, Any]:
        """Extract video metadata without downloading."""
        # Uses yt-dlp to extract metadata from any supported platform
    
    def download_video(self, url: str, output_path: str, progress_callback: Optional[Callable] = None) -> dict[str, Any]:
        """Download video from any supported platform URL."""
        # Downloads video with best quality H.264 codec for browser compatibility
    
    def process_youtube_url_sync(self, url: str, db: Session, user: User, media_file: MediaFile, progress_callback: Optional[Callable] = None) -> MediaFile:
        """Process a media URL by downloading and updating MediaFile record."""
        # Complete pipeline: download â†’ metadata extraction â†’ storage â†’ database update
```

### Supported Platforms
The service supports **1000+ video platforms** via yt-dlp, including:
- **YouTube** - Videos and playlists
- **Vimeo** - Video hosting platform
- **Twitter/X** - Video tweets and spaces
- **TikTok** - Short-form videos
- **Instagram** - Video posts and reels
- **Facebook** - Video content
- **Twitch** - Live streams and clips
- **And 1000+ more platforms** - See [yt-dlp supported sites](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md)

### Features
- **Universal URL Support**: Accepts any HTTP/HTTPS URL and automatically detects the platform
- **Automatic Source Detection**: Identifies the platform from URL and extracts appropriate metadata
- **Metadata Extraction**: Extracts title, description, uploader, duration, and other metadata
- **Quality Optimization**: Downloads best H.264 quality for maximum browser compatibility
- **Progress Tracking**: Real-time download progress with callbacks
- **Thumbnail Handling**: Downloads and stores video thumbnails when available
- **Playlist Support**: Handles YouTube playlists with batch processing
- **Error Handling**: Comprehensive error handling with user-friendly messages

### Usage Example
```python
# In API endpoint
@router.post("/files/process-url")
async def process_media_url(
    request_data: URLProcessingRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    youtube_service = YouTubeService()
    
    # Validate URL (accepts any HTTP/HTTPS URL)
    if not youtube_service.is_valid_youtube_url(request_data.url):
        raise HTTPException(status_code=400, detail="Invalid URL")
    
    # Extract video info
    video_info = youtube_service.extract_video_info(request_data.url)
    
    # Process and download
    media_file = youtube_service.process_youtube_url_sync(
        url=request_data.url,
        db=db,
        user=current_user,
        media_file=placeholder_media_file
    )
    
    return media_file
```

### Technical Details
- **Library**: Uses `yt-dlp` (fork of youtube-dl) for universal platform support
- **Format Selection**: Prioritizes H.264 codec for maximum browser compatibility
- **File Size Limit**: 15GB maximum (matches upload limit)
- **Duration Limit**: 4 hours maximum per video
- **Output Format**: MP4 with web-compatible encoding
- **Metadata Storage**: Stores platform-specific metadata in `metadata_raw` field
- **Source Tracking**: Automatically detects and stores platform source (e.g., "vimeo", "twitter", "youtube")

### Error Handling
```python
try:
    video_info = youtube_service.extract_video_info(url)
except HTTPException as e:
    # Platform not supported or URL invalid
    # Returns 400 with descriptive error message
    pass
```

## ðŸ“‹ Task Filtering Service (`task_filtering_service.py`)

### Purpose
Optimizes data retrieval and filtering for improved performance and user experience.

### Key Operations
```python
class TaskFilteringService:
    @staticmethod
    def filter_tasks_by_criteria(db: Session, user_id: int, criteria: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Filter tasks based on various criteria."""

    @staticmethod
    def optimize_query_performance(query: Any) -> Any:
        """Optimize database queries for better performance."""
```

### Filtering Features
- **Efficient Data Retrieval**: Optimized database queries
- **Multi-Criteria Filtering**: Complex filtering logic
- **Performance Optimization**: Query optimization for large datasets
- **User-Specific Filtering**: Context-aware filtering based on user permissions

## ðŸ” OpenSearch Service (`opensearch_service.py`)

### Purpose
Manages full-text search, indexing, and search analytics for transcripts and files.

### Key Operations
```python
def index_transcript(file_id: int, user_id: int, full_transcript: str, speaker_names: List[str], file_title: str) -> None:
    """Index transcript for full-text search."""
    
def search_transcripts(user_id: int, query: str, filters: dict = None) -> List[Dict]:
    """Search across user's transcripts."""
    
def add_speaker_embedding(speaker_id: int, embedding_vector: List[float]) -> None:
    """Store speaker voice embedding for similarity search."""
    
def search_similar_speakers(embedding_vector: List[float], user_id: int) -> List[Dict]:
    """Find similar speakers using vector search."""
```

### Search Features
```python
def build_search_query(query: str, filters: dict) -> Dict:
    """Build complex OpenSearch query."""
    search_body = {
        "query": {
            "bool": {
                "must": [
                    {"match": {"transcript": query}}
                ],
                "filter": []
            }
        },
        "highlight": {
            "fields": {"transcript": {}}
        }
    }
    
    # Add filters (date range, speakers, file types, etc.)
    if filters.get('from_date'):
        search_body["query"]["bool"]["filter"].append({
            "range": {"created_at": {"gte": filters['from_date']}}
        })
    
    return search_body
```

### Features
- **Full-text Search**: Advanced search across transcripts
- **Faceted Search**: Filter by speakers, dates, file types
- **Highlighting**: Search term highlighting in results
- **Vector Search**: Speaker similarity using voice embeddings
- **Analytics**: Search performance and usage analytics

## ðŸ”„ Service Integration Patterns

### Cross-Service Operations
```python
class FileService:
    def delete_file(self, file_id: int, user: User) -> None:
        """Complete file deletion across all services."""
        try:
            # 1. Get file information
            file_obj = self._get_file_with_permission_check(file_id, user)
            
            # 2. Delete from object storage
            minio_service.delete_file(file_obj.storage_path)
            
            # 3. Remove from search index
            opensearch_service.delete_document(file_id)
            
            # 4. Cancel any running tasks
            transcription_service.cancel_file_tasks(file_id)
            
            # 5. Delete from database (cascades to related records)
            self.db.delete(file_obj)
            self.db.commit()
            
        except Exception as e:
            self.db.rollback()
            raise self._handle_deletion_error(e)
```

### Service Dependencies
```python
# Services can call other services when needed
class TranscriptionService:
    def __init__(self, db: Session):
        self.db = db
        self.file_service = FileService(db)  # Dependency injection
    
    def start_transcription(self, file_id: int, user: User):
        # Use file service for validation
        file_obj = self.file_service.get_file_by_id(file_id, user)
        # Continue with transcription logic...
```

## ðŸ§ª Testing Services

### Service Testing Patterns
```python
class TestFileService:
    def test_upload_file_success(self, db_session, mock_user, mock_upload_file):
        """Test successful file upload."""
        file_service = FileService(db_session)
        
        # Mock external dependencies
        with patch('app.services.minio_service.upload_file'):
            result = await file_service.upload_file(mock_upload_file, mock_user)
            
        assert result.filename == mock_upload_file.filename
        assert result.user_id == mock_user.id
    
    def test_delete_file_unauthorized(self, db_session, mock_user, other_user_file):
        """Test unauthorized file deletion."""
        file_service = FileService(db_session)
        
        with pytest.raises(HTTPException) as exc_info:
            file_service.delete_file(other_user_file.id, mock_user)
            
        assert exc_info.value.status_code == 403
```

### Mocking External Services
```python
# Mock external service calls in tests
@patch('app.services.minio_service.upload_file')
@patch('app.services.opensearch_service.index_transcript')
def test_complete_transcription_workflow(mock_opensearch, mock_minio, db_session):
    """Test full transcription workflow with mocked external services."""
    # Test logic without actual external API calls
```

## ðŸ“Š Error Handling in Services

### Standardized Error Responses
```python
from app.utils.error_handlers import ErrorHandler

class FileService:
    def get_file_by_id(self, file_id: int, user: User) -> MediaFile:
        """Get file with proper error handling."""
        file_obj = self.db.query(MediaFile).filter(
            MediaFile.id == file_id,
            MediaFile.user_id == user.id
        ).first()
        
        if not file_obj:
            raise ErrorHandler.not_found_error("File")
        
        return file_obj
    
    def _handle_upload_error(self, error: Exception) -> None:
        """Handle upload-specific errors."""
        if isinstance(error, MinIOError):
            raise ErrorHandler.file_processing_error("storage upload", error)
        elif isinstance(error, ValidationError):
            raise ErrorHandler.validation_error(str(error))
        else:
            raise ErrorHandler.database_error("file creation", error)
```

## ðŸš€ Performance Considerations

### Database Optimization
```python
class FileService:
    def get_user_files_with_stats(self, user: User) -> List[Dict]:
        """Optimized query with eager loading."""
        return self.db.query(MediaFile)\
            .options(
                joinedload(MediaFile.transcript_segments),
                joinedload(MediaFile.comments),
                selectinload(MediaFile.file_tags).joinedload(FileTag.tag)
            )\
            .filter(MediaFile.user_id == user.id)\
            .all()
```

### Caching Strategies
```python
from functools import lru_cache

class TranscriptionService:
    @lru_cache(maxsize=100)
    def get_user_speakers_cached(self, user_id: int) -> List[Speaker]:
        """Cache frequently accessed speaker data."""
        return self.db.query(Speaker)\
            .filter(Speaker.user_id == user_id)\
            .all()
```

## ðŸ”§ Adding New Services

### Service Creation Checklist
1. **Define Purpose**: Clear single responsibility
2. **Design Interface**: Public methods and their signatures
3. **Error Handling**: Use standardized error patterns
4. **Dependencies**: Inject required services/utilities
5. **Testing**: Comprehensive unit tests with mocks
6. **Documentation**: Clear docstrings and examples

### Service Template
```python
from typing import List, Optional
from sqlalchemy.orm import Session

from app.models.user import User
from app.utils.error_handlers import ErrorHandler
from app.utils.auth_decorators import AuthorizationHelper

class NewService:
    """Service for handling [specific domain] operations."""
    
    def __init__(self, db: Session):
        self.db = db
    
    def create_resource(self, data: CreateSchema, user: User) -> Resource:
        """Create a new resource with validation."""
        try:
            # Validation
            self._validate_create_data(data)
            
            # Business logic
            resource = self._perform_create_operation(data, user)
            
            # Database transaction
            self.db.add(resource)
            self.db.commit()
            self.db.refresh(resource)
            
            return resource
            
        except Exception as e:
            self.db.rollback()
            raise self._handle_create_error(e)
    
    def _validate_create_data(self, data: CreateSchema) -> None:
        """Private validation method."""
        # Validation logic
        pass
    
    def _handle_create_error(self, error: Exception) -> None:
        """Private error handling method."""
        # Error handling logic
        pass
```

---

The services layer provides a clean, testable, and maintainable way to implement business logic while keeping API endpoints focused on HTTP concerns and database models focused on data representation.