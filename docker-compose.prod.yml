# OpenTranscribe Production Overrides
# Use with: docker compose -f docker-compose.yml -f docker-compose.prod.yml up
#
# This file contains ONLY production-specific settings:
#   - Pull pre-built images from Docker Hub
#   - Production volume configurations
#   - Production database initialization path

services:
  backend:
    image: davidamacey/opentranscribe-backend:latest
    # build: removed - use pre-built image from Docker Hub
    # If image doesn't exist, it will be pulled automatically
    pull_policy: missing
    # No volumes needed - temp files live in container only

  celery-worker:
    image: davidamacey/opentranscribe-backend:latest
    # All backend services share the same image - saves overlay2 space
    pull_policy: missing
    volumes:
      # Production: only model cache, no code mounts
      - ${MODEL_CACHE_DIR:-./models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-./models}/torch:/home/appuser/.cache/torch
      - ${MODEL_CACHE_DIR:-./models}/nltk_data:/home/appuser/.cache/nltk_data
      - ${MODEL_CACHE_DIR:-./models}/sentence-transformers:/home/appuser/.cache/sentence-transformers
      # No temp volume needed - temp files live in container only

  celery-download-worker:
    image: davidamacey/opentranscribe-backend:latest
    # Shares same image as other backend services
    pull_policy: missing
    volumes:
      # Production: only model cache for download worker
      - ${MODEL_CACHE_DIR:-./models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-./models}/torch:/home/appuser/.cache/torch

  celery-cpu-worker:
    image: davidamacey/opentranscribe-backend:latest
    # Shares same image as other backend services
    pull_policy: missing
    # No volumes needed - CPU worker doesn't need model cache

  celery-nlp-worker:
    image: davidamacey/opentranscribe-backend:latest
    # Shares same image as other backend services
    pull_policy: missing
    # No volumes needed - NLP worker doesn't need model cache

  celery-beat:
    image: davidamacey/opentranscribe-backend:latest
    # Shares same image as other backend services
    pull_policy: missing
    # No volumes needed - scheduler state lives in container only

  frontend:
    image: davidamacey/opentranscribe-frontend:latest
    # build: removed - use pre-built image from Docker Hub
    pull_policy: missing
    ports:
      - "${FRONTEND_PORT:-5173}:8080"  # Production NGINX port
    environment:
      - NODE_ENV=production  # Production mode
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://127.0.0.1:8080"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  flower:
    image: davidamacey/opentranscribe-backend:latest
    # Shares same image as other backend services
    pull_policy: missing

  # GPU Scaled Worker - Production overrides
  # Base definition in docker-compose.yml, GPU config in docker-compose.gpu-scale.yml
  celery-worker-gpu-scaled:
    image: davidamacey/opentranscribe-backend:latest  # Shares same image as other backend services
    pull_policy: missing
    volumes:
      # Production: Model cache directories only (no code mount)
      - ${MODEL_CACHE_DIR:-./models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-./models}/torch:/home/appuser/.cache/torch
      - ${MODEL_CACHE_DIR:-./models}/nltk_data:/home/appuser/.cache/nltk_data
      - ${MODEL_CACHE_DIR:-./models}/sentence-transformers:/home/appuser/.cache/sentence-transformers
