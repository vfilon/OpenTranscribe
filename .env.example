# OpenTranscribe Environment Configuration
#
# SECURITY NOTICE: This is a template file with placeholder values.
# DO NOT use these placeholder values in production!
#
# For new installations:
# - Linux/Mac: ./setup-opentranscribe.sh will auto-generate secure passwords
# - Windows: The installer will auto-generate secure passwords
# - Manual: Copy this file to .env and replace ALL placeholder values
#
# All secrets are auto-generated during installation for maximum security.
# You can customize values in .env after installation if needed.

#=============================================================================
# DATABASE CONFIGURATION
#=============================================================================

# PostgreSQL Database Settings
POSTGRES_HOST=postgres
POSTGRES_PORT=5176
POSTGRES_USER=postgres
# CRITICAL: Auto-generated during install (32-char random hex)
POSTGRES_PASSWORD=CHANGE_ME_auto_generated_on_install
POSTGRES_DB=opentranscribe

# Database Initialization SQL Path
# Development: ./database/init_db.sql (relative to repo root)
# Production/Offline: ./init_db.sql (relative to installation directory)
# This is automatically set by installation scripts
INIT_DB_PATH=./database/init_db.sql

#=============================================================================
# OBJECT STORAGE (MinIO S3-Compatible)
#=============================================================================

# MinIO Storage Settings
MINIO_HOST=minio
MINIO_PORT=5178
MINIO_CONSOLE_PORT=5179
# CRITICAL: Auto-generated during install (32-char random hex)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=CHANGE_ME_auto_generated_on_install
MEDIA_BUCKET_NAME=opentranscribe

#=============================================================================
# REDIS CACHE & MESSAGE BROKER
#=============================================================================

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=5177
# OPTIONAL: Set a password for Redis (recommended for production)
# Auto-generated during install (32-char random hex)
# Leave empty to disable Redis authentication (not recommended for production)
REDIS_PASSWORD=CHANGE_ME_auto_generated_on_install

#=============================================================================
# SEARCH ENGINE (OpenSearch)
#=============================================================================

# OpenSearch Configuration
OPENSEARCH_HOST=opensearch
OPENSEARCH_PORT=5180
OPENSEARCH_ADMIN_PORT=5181
# OPTIONAL: OpenSearch credentials (currently security plugin is disabled)
# Enable for production by setting DISABLE_SECURITY_PLUGIN=false in docker-compose
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=CHANGE_ME_auto_generated_on_install

#=============================================================================
# SECURITY & AUTHENTICATION
#=============================================================================

# JWT Token Configuration
# CRITICAL: Used for user session authentication
# Auto-generated during install (64-char random hex for maximum security)
JWT_SECRET_KEY=CHANGE_ME_auto_generated_on_install
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=1440

# API Key Encryption
# CRITICAL: Used to encrypt LLM API keys stored in database
# Auto-generated during install (random string with prefix to ensure proper backend processing)
# NEVER change this after first use or encrypted data will be lost!
# To manually generate: echo "opentranscribe_$(openssl rand -base64 48)"
ENCRYPTION_KEY=CHANGE_ME_auto_generated_on_install

# LDAP/Active Directory Authentication (Optional)
# Set to 'true' to enable LDAP authentication alongside local users
LDAP_ENABLED=false
# LDAP server address (use ldap:// for standard LDAP, ldaps:// for secure LDAP)
LDAP_SERVER=ldaps://your-ad-server.domain.com
# LDAP server port (389 for standard LDAP, 636 for LDAPS)
LDAP_PORT=636
# Use LDAPS (LDAP over SSL) - recommended for production
LDAP_USE_SSL=true
# Use StartTLS (alternative to LDAPS)
LDAP_USE_TLS=false
# Bind DN for LDAP service account (used to search for users)
# Example: CN=service-account,CN=Users,DC=domain,DC=com
LDAP_BIND_DN=CN=service-account,CN=Users,DC=domain,DC=com
# Bind password for LDAP service account
LDAP_BIND_PASSWORD=your-service-account-password
# Base DN for user searches
# Example: DC=domain,DC=com or OU=Users,DC=domain,DC=com
LDAP_SEARCH_BASE=DC=domain,DC=com
# LDAP username attribute (sAMAccountName for Active Directory, uid for OpenLDAP)
LDAP_USERNAME_ATTR=sAMAccountName
# LDAP search filter to find users by username
# {username} will be replaced with the login username
LDAP_USER_SEARCH_FILTER=({username_attr}={username})
# LDAP attribute containing user email (mail for AD, mail for OpenLDAP)
LDAP_EMAIL_ATTR=mail
# LDAP attribute containing user full name (cn for AD, cn for OpenLDAP)
LDAP_NAME_ATTR=cn
# Connection timeout in seconds
LDAP_TIMEOUT=10
# Comma-separated list of AD usernames that should be admin users
# Example: admin1,admin2,john.doe
LDAP_ADMIN_USERS=

# Comma-separated list of MediaCMS hostnames handled by the protected media plugin
# Example: MEDIACMS_ALLOWED_HOSTS=media.example.com,mediacms.internal
MEDIACMS_ALLOWED_HOSTS=
#=============================================================================
# APPLICATION PORTS (External Access)
#=============================================================================

# External port configuration (accessible from host machine)
# Consistent ports across all environments to avoid confusion
FRONTEND_PORT=5173          # Web UI
BACKEND_PORT=5174           # API Server
FLOWER_PORT=5175            # Celery Task Monitor
POSTGRES_PORT=5176          # Database (for admin tools)
REDIS_PORT=5177             # Redis (for debugging)
MINIO_PORT=5178             # MinIO API
MINIO_CONSOLE_PORT=5179     # MinIO Web Console
OPENSEARCH_PORT=5180        # OpenSearch API
OPENSEARCH_ADMIN_PORT=5181  # OpenSearch Admin

#=============================================================================
# AI MODEL STORAGE & CACHING
#=============================================================================

# Model Cache Directory (on host machine)
# This directory persists AI models between container restarts (~2-6GB total)
MODEL_CACHE_DIR=./models

# Container Internal Paths (do not change unless you know what you're doing)
MODEL_BASE_DIR=/app/models
MODELS_DIRECTORY=/app/models
TEMP_DIR=/app/temp

#=============================================================================
# HARDWARE DETECTION & GPU CONFIGURATION
#=============================================================================

# Hardware Configuration (auto-detected by setup scripts)
# Options: auto, cuda, mps, cpu
TORCH_DEVICE=auto

# Compute Type (auto-detected based on GPU capabilities)
# Options: auto, float16, float32, int8
COMPUTE_TYPE=auto

# GPU Usage (auto-detected)
# Options: auto, true, false
USE_GPU=auto

# GPU Device Selection (for multi-GPU systems)
# Selects which GPU to use (0 = first GPU, 1 = second GPU, etc.)
GPU_DEVICE_ID=0

# Batch Size (auto-detected based on available GPU memory)
# Options: auto, or specific number (1, 8, 16, 32)
BATCH_SIZE=auto

# Multi-GPU Worker Scaling (Optional - Advanced Feature)
# Enable this to run multiple parallel GPU workers on a dedicated GPU device
# This significantly increases transcription throughput for multi-GPU systems
# Example: GPU 0 = LLM, GPU 1 = Single transcription worker, GPU 2 = 4 parallel workers
#
# GPU_SCALE_ENABLED: Set to 'true' to enable multi-GPU scaling (default: false)
# GPU_SCALE_DEVICE_ID: Which GPU device to use for scaled workers (default: 2)
# GPU_SCALE_WORKERS: Number of parallel workers on the scaled GPU (default: 4)
#
# Usage: ./opentr.sh start dev --gpu-scale
# Or manually: docker compose -f docker-compose.yml -f docker-compose.gpu-scale.yml up
GPU_SCALE_ENABLED=false
GPU_SCALE_DEVICE_ID=2
GPU_SCALE_WORKERS=4

#=============================================================================
# AI MODELS CONFIGURATION
#=============================================================================

# Whisper Speech Recognition Model
# Options: tiny, base, small, medium, large-v1, large-v2, large-v3
# Larger models = better accuracy but slower and more VRAM
# Recommended: large-v2 for GPU, small for CPU
WHISPER_MODEL=large-v2

# Speaker Diarization Model
DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
MIN_SPEAKERS=1
MAX_SPEAKERS=20  # Can be increased to 50+ for large conferences (no hard limit)

# HuggingFace Token (REQUIRED for speaker diarization)
# Get your token at: https://huggingface.co/settings/tokens
# You must accept PyAnnote model terms at: https://huggingface.co/pyannote/speaker-diarization-3.1
HUGGINGFACE_TOKEN=

#=============================================================================
# LLM PROVIDER CONFIGURATION (Optional - for AI Summarization)
#=============================================================================

# LLM Provider Selection
# IMPORTANT: Users configure LLM providers through the Web UI (Settings → LLM Provider)
# This is a system-wide default fallback when no user settings exist
#
# Options: vllm, openai, ollama, anthropic, openrouter, or leave empty
# Leave empty for transcription-only mode (no AI summarization/speaker identification)
LLM_PROVIDER=

# ─────────────────────────────────────────────────────────────────────────
# vLLM (Self-Hosted Open Source LLM Server)
# ─────────────────────────────────────────────────────────────────────────
VLLM_BASE_URL=http://localhost:8012/v1
VLLM_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2
VLLM_API_KEY=

# ─────────────────────────────────────────────────────────────────────────
# OpenAI (Commercial Cloud API)
# ─────────────────────────────────────────────────────────────────────────
OPENAI_API_KEY=
OPENAI_MODEL_NAME=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# ─────────────────────────────────────────────────────────────────────────
# Ollama (Self-Hosted Local LLM)
# ─────────────────────────────────────────────────────────────────────────
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=llama2:7b-chat

# ─────────────────────────────────────────────────────────────────────────
# Anthropic Claude (Commercial Cloud API)
# ─────────────────────────────────────────────────────────────────────────
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL_NAME=claude-3-haiku-20240307
ANTHROPIC_BASE_URL=https://api.anthropic.com

# ─────────────────────────────────────────────────────────────────────────
# OpenRouter (Multi-Provider API Gateway)
# ─────────────────────────────────────────────────────────────────────────
OPENROUTER_API_KEY=
OPENROUTER_MODEL_NAME=anthropic/claude-3-haiku
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

#=============================================================================
# FRONTEND CONFIGURATION
#=============================================================================

# Node Environment
NODE_ENV=production

# API Connection URLs (used by frontend to connect to backend)
VITE_API_BASE_URL=http://localhost:5174/api
VITE_WS_BASE_URL=ws://localhost:5174/ws

# Flower (Celery Task Monitor) Configuration
VITE_FLOWER_PORT=5175
VITE_FLOWER_URL_PREFIX=flower

#=============================================================================
# ADVANCED CONFIGURATION (Internal Docker Settings)
#=============================================================================
# The following variables are used internally by Docker containers
# and typically don't need to be changed unless you're doing advanced customization

# Internal service hostnames (Docker Compose service names)
# These are DNS names within the Docker network
# POSTGRES_HOST=postgres (already set above)
# MINIO_HOST=minio (already set above)
# REDIS_HOST=redis (already set above)
# OPENSEARCH_HOST=opensearch (already set above)

# Celery Configuration (auto-configured from REDIS settings)
# CELERY_BROKER_URL is automatically constructed from REDIS_HOST, REDIS_PORT, REDIS_PASSWORD
# CELERY_RESULT_BACKEND is automatically constructed from REDIS_HOST, REDIS_PORT, REDIS_PASSWORD

# Database URL (auto-constructed from POSTGRES_* variables)
# DATABASE_URL is automatically built by the backend from individual POSTGRES_* settings

#=============================================================================
# NGINX REVERSE PROXY (Optional - for HTTPS/SSL)
#=============================================================================
# NGINX provides HTTPS access, which is REQUIRED for:
# - Browser microphone recording (browsers block mic access over HTTP)
# - Secure access from other devices on your network
# - Production deployments with custom domains
#
# Quick Setup for Homelab:
# 1. Generate certificates: ./scripts/generate-ssl-cert.sh opentranscribe.local --auto-ip
# 2. Uncomment and set NGINX_SERVER_NAME below
# 3. Run: ./opentr.sh start dev (auto-detects NGINX and adds the overlay)
# 4. Trust the certificate on client devices (see docs/NGINX_SETUP.md)
#
# For production with Let's Encrypt, see docs/NGINX_SETUP.md

# Primary hostname for NGINX (uncomment to enable NGINX)
# Examples: opentranscribe.local, transcribe.home, myserver.example.com
# NGINX_SERVER_NAME=opentranscribe.local

# Optional: Custom ports (defaults: 80 for HTTP redirect, 443 for HTTPS)
# NGINX_HTTP_PORT=80
# NGINX_HTTPS_PORT=443

# Optional: Custom certificate paths (defaults to ./nginx/ssl/server.crt and .key)
# NGINX_CERT_FILE=./nginx/ssl/server.crt
# NGINX_CERT_KEY=./nginx/ssl/server.key

#=============================================================================
# OFFLINE/AIR-GAPPED DEPLOYMENT
#=============================================================================
# For offline deployments, the installer will set these automatically

# HuggingFace Hub Offline Mode
# HF_HUB_OFFLINE=1

# Note: TEMP_DIR=/app/temp is set by default (line 115) and should NOT be overridden
# All containers use /app/temp internally (no host mapping) for proper permissions
