# OpenTranscribe Base Configuration
# This file contains common configuration for all environments
#
# Usage:
#   Development:   docker compose up (auto-loads docker-compose.override.yml)
#   Production:    docker compose -f docker-compose.yml -f docker-compose.prod.yml up
#   Offline:       docker compose -f docker-compose.yml -f docker-compose.offline.yml up

services:
  postgres:
    container_name: opentranscribe-postgres
    image: postgres:17.5-alpine
    restart: always
    env_file: .env
    volumes:
      - postgres_data:/var/lib/postgresql/data/
      - ${INIT_DB_PATH:-./database/init_db.sql}:/docker-entrypoint-initdb.d/init_db.sql:ro
    ports:
      - "${POSTGRES_PORT:-5176}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 5s
      timeout: 5s
      retries: 5

  minio:
    container_name: opentranscribe-minio
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z
    restart: always
    env_file: .env
    volumes:
      - minio_data:/data
    ports:
      - "${MINIO_PORT:-5178}:9000"
      - "${MINIO_CONSOLE_PORT:-5179}:9001"
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 10s
      retries: 5

  redis:
    container_name: opentranscribe-redis
    image: redis:8.2.2-alpine3.22
    restart: always
    env_file: .env
    ports:
      - "${REDIS_PORT:-5177}:6379"
    volumes:
      - redis_data:/data
    # Use password if REDIS_PASSWORD is set in .env
    command: >
      sh -c "if [ -n \"$REDIS_PASSWORD\" ]; then
        redis-server --requirepass \"$REDIS_PASSWORD\";
      else
        redis-server;
      fi"
    healthcheck:
      test: >
        sh -c "if [ -n \"$REDIS_PASSWORD\" ]; then
          redis-cli -a \"$REDIS_PASSWORD\" ping;
        else
          redis-cli ping;
        fi"
      interval: 5s
      timeout: 30s
      retries: 50

  opensearch:
    container_name: opentranscribe-opensearch
    image: opensearchproject/opensearch:3.3.1
    restart: always
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - DISABLE_SECURITY_PLUGIN=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    ports:
      - "${OPENSEARCH_PORT:-5180}:9200"
      - "${OPENSEARCH_ADMIN_PORT:-5181}:9600"
    healthcheck:
      test: ["CMD-SHELL", "curl -sS http://localhost:9200 || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 20

  backend:
    container_name: opentranscribe-backend
    restart: always
    env_file: .env
    # Backend handles API requests only - no AI models needed
    # AI processing happens in celery-worker service
    ports:
      - "${BACKEND_PORT:-5174}:8080"
    environment:
      # Internal Docker network settings (hardcoded for service-to-service communication)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      # Container paths (hardcoded for internal use)
      - MODELS_DIRECTORY=/app/models
      - MODEL_BASE_DIR=/app/models
      - TEMP_DIR=/app/temp
    tmpfs:
      - /app/temp:noexec,nosuid,size=4g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      opensearch:
        condition: service_healthy

  celery-worker:
    container_name: opentranscribe-celery-worker
    restart: always
    env_file: .env
    command: celery -A app.core.celery worker --loglevel=info -Q gpu --concurrency=1
    # GPU configuration is provided by docker-compose.gpu.yml overlay
    # when NVIDIA GPU is detected (automatically handled by opentr.sh)
    volumes:
      # Model cache directories - must be owned by UID 1000 on host
      - ${MODEL_CACHE_DIR:-./models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-./models}/torch:/home/appuser/.cache/torch
      - ${MODEL_CACHE_DIR:-./models}/nltk_data:/home/appuser/.cache/nltk_data
      - ${MODEL_CACHE_DIR:-./models}/sentence-transformers:/home/appuser/.cache/sentence-transformers
    environment:
      # Internal Docker network settings (same as backend)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - MODELS_DIRECTORY=/app/models
      - MODEL_BASE_DIR=/app/models
      - TEMP_DIR=/app/temp
    tmpfs:
      - /app/temp:noexec,nosuid,size=20g
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.core.celery inspect ping -d celery@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      - postgres
      - redis
      - minio
      - opensearch

  celery-download-worker:
    container_name: opentranscribe-celery-download-worker
    restart: always
    env_file: .env
    command: celery -A app.core.celery worker --loglevel=info -Q download --concurrency=3 --max-tasks-per-child=10
    volumes:
      - ${MODEL_CACHE_DIR:-./models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-./models}/torch:/home/appuser/.cache/torch
    environment:
      # Internal Docker network settings (same as backend)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - TEMP_DIR=/app/temp
    tmpfs:
      - /app/temp:noexec,nosuid,size=15g
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.core.celery inspect ping -d celery@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      - postgres
      - redis
      - minio
      - opensearch

  celery-cpu-worker:
    container_name: opentranscribe-celery-cpu-worker
    restart: always
    env_file: .env
    command: celery -A app.core.celery worker --loglevel=info -Q cpu,utility --concurrency=8 --max-tasks-per-child=20
    environment:
      # Internal Docker network settings (same as backend)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - TEMP_DIR=/app/temp
    tmpfs:
      - /app/temp:noexec,nosuid,size=5g
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.core.celery inspect ping -d celery@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      - postgres
      - redis
      - minio
      - opensearch

  celery-nlp-worker:
    container_name: opentranscribe-celery-nlp-worker
    restart: always
    env_file: .env
    command: celery -A app.core.celery worker --loglevel=info -Q nlp,celery --concurrency=4 --max-tasks-per-child=50
    environment:
      # Internal Docker network settings (same as backend)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - TEMP_DIR=/app/temp
    tmpfs:
      - /app/temp:noexec,nosuid,size=5g
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.core.celery inspect ping -d celery@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      - postgres
      - redis
      - minio
      - opensearch

  celery-beat:
    container_name: opentranscribe-celery-beat
    restart: always
    env_file: .env
    command: celery -A app.core.celery beat --loglevel=info
    environment:
      # Internal Docker network settings (same as backend)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - TEMP_DIR=/app/temp
    tmpfs:
      - /app/temp:noexec,nosuid,size=1g
    healthcheck:
      test: ["CMD-SHELL", "python3 -c 'import os,time; exit(0 if os.path.exists(\"/app/celerybeat-schedule\") and time.time()-os.path.getmtime(\"/app/celerybeat-schedule\")<300 else 1)'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      - postgres
      - redis

  # GPU Scaled Worker - Base definition
  # Activated only with --gpu-scale flag (profile: gpu-scale)
  # Specific settings (command, GPU config) in docker-compose.gpu-scale.yml
  # Image/build/volumes in override.yml (dev), prod.yml, or offline.yml
  celery-worker-gpu-scaled:
    container_name: ${COMPOSE_PROJECT_NAME:-opentranscribe}-celery-worker-gpu-scaled
    profiles:
      - gpu-scale  # Only activated with --gpu-scale flag
    scale: 0  # Disabled by default, gpu-scale.yml sets scale: 1
    restart: always
    env_file: .env
    environment:
      # Internal Docker network settings (same as other workers)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - MODELS_DIRECTORY=/app/models
      - MODEL_BASE_DIR=/app/models
      - TEMP_DIR=/app/temp
    tmpfs:
      - /app/temp:noexec,nosuid,size=20g
    depends_on:
      - postgres
      - redis
      - minio
      - opensearch

  frontend:
    container_name: opentranscribe-frontend
    restart: always
    env_file: .env
    # Note: ports, healthcheck, and NODE_ENV defined in override files (dev vs prod)
    depends_on:
      backend:
        condition: service_healthy

  flower:
    container_name: opentranscribe-flower
    restart: always
    env_file: .env
    command: >
      python -m celery -A app.core.celery flower
      --port=5555
      --url_prefix=${VITE_FLOWER_URL_PREFIX:-flower}
      --persistent=True
      --db=/app/flower.db
      --broker=redis://${REDIS_PASSWORD:+:${REDIS_PASSWORD}@}redis:6379/0
    ports:
      - "${FLOWER_PORT:-5175}:5555"
    environment:
      - CELERY_BROKER_URL=redis://${REDIS_PASSWORD:+:${REDIS_PASSWORD}@}redis:6379/0
      - TEMP_DIR=/app/temp
    depends_on:
      - redis
      - celery-worker
    volumes:
      # Flower only needs persistent database for monitoring, not AI models
      - flower_data:/app
    tmpfs:
      - /app/temp:noexec,nosuid,size=1g

volumes:
  postgres_data:
  minio_data:
  redis_data:
  opensearch_data:
  flower_data:

networks:
  default:
    driver: bridge
